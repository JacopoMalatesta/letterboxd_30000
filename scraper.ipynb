{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research questions:\n",
    "- What are the producers with the highest number of 4-rated films?\n",
    "- What are the studios with the highest number of 4-rated films?\n",
    "- Is there a correlation between runtime and rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import backoff\n",
    "import concurrent.futures\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import itertools\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT \n",
    "import sqlalchemy\n",
    "import custom_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the links, the film ids and the film ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of pages in the playlist with all the ratings (we'll iterate over this number in the following for loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(requests.get(\"https://letterboxd.com/mereghetti/films/ratings/\").content, 'lxml')\n",
    "\n",
    "n_of_pages = int(soup.select(\"#content > div > div > section > div.pagination > div.paginate-pages > ul > li:nth-child(5) > a\")[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store all the URLs in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://letterboxd.com/mereghetti/films/ratings/page/{0}/\"\n",
    "\n",
    "urls = [url.format(i) for i in range(1, n_of_pages + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a co-routine to send an HTTP 'get' request and fetch the HTML code of each URL. We'll also use a decorator to retry on errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@backoff.on_exception(backoff.expo, aiohttp.ClientError, max_time=600)\n",
    "async def fetch(session, url):\n",
    "    async with session.get(url) as r:\n",
    "        if r.status != 200:\n",
    "            print(f\"{r.status} for {url}\")\n",
    "        else:\n",
    "            return await r.text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the event-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_all():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch(session, url) for url in urls]\n",
    "        https = await asyncio.gather(*tasks)\n",
    "        return https"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the event loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = await fetch_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse every HTML page into a BeautifulSoup object by using multi-processing. \n",
    "\n",
    "I ran some tests and found that this operation is faster with multi-processing than with multi-threading (it's likely to be more of a CPU-bound task rather than an I/O-bound one).\n",
    "\n",
    "I'll set the chunksize to 1 to speed things up a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.355295181274414\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "def soupify_all():\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    with concurrent.futures.ProcessPoolExecutor() as pool:\n",
    "        for result in pool.map(custom_functions.soupify, pages, chunksize = 1):\n",
    "            results.append(result)\n",
    "        \n",
    "    return results\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    soups = soupify_all()\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the film URLs, the film IDs and the ratings out of every BeautifulSoup object.\n",
    "\n",
    "This loop is fast so there's no need to run it in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.460731267929077\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "links = []\n",
    "ids = []\n",
    "ratings = []\n",
    "\n",
    "\n",
    "for soup in soups:\n",
    "    divs = soup.find_all(\"div\", class_ = \"really-lazy-load\")\n",
    "    links_list = [\"https://letterboxd.com\" + div.get(\"data-film-slug\") for div in divs]\n",
    "    links.append(links_list)\n",
    "    \n",
    "    divs = soup.find_all(\"div\", class_ = \"really-lazy-load\")\n",
    "    ids_list = [int(div.get(\"data-film-id\")) for div in divs]\n",
    "    ids.append(ids_list)\n",
    "    \n",
    "    rated = [span.get(\"class\")[1] for span in soup.find_all(\"span\", class_ = \"rating\")]\n",
    "    ratings_list = [int(re.findall(r'\\d+', r)[0]) for r in rated]\n",
    "    ratings.append(ratings_list)\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lists returned by the previous loop are nested (i.e. lists consisting of other lists). Let's unlist them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = list(itertools.chain(*links))\n",
    "ids = list(itertools.chain(*ids))\n",
    "ratings = list(itertools.chain(*ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape additional film data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This event loop will allow us to fetch the HTML page for each film in our 'links' list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110.23596787452698\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "async def fetch_all():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch(session, link) for link in links]\n",
    "        https = await asyncio.gather(*tasks)\n",
    "        return https\n",
    "    \n",
    "film_pages = await fetch_all()\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the HTML pages into BeautifulSoup objects like we did previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1416.7062947750092\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "def soupify_all():\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    with concurrent.futures.ProcessPoolExecutor() as pool:\n",
    "        for result in pool.map(custom_functions.soupify, film_pages, chunksize = 1):\n",
    "            results.append(result)\n",
    "        \n",
    "    return results\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    soups = soupify_all()\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate all our functions with a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008.003270149231\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "titles = []\n",
    "years = []\n",
    "ids_two = []\n",
    "directors = []\n",
    "cast = []\n",
    "countries = []\n",
    "genres = []\n",
    "production_companies = []\n",
    "runtimes = []\n",
    "languages = []\n",
    "alt_titles = []\n",
    "producers = []\n",
    "writers = []\n",
    "editors = []\n",
    "cinematographers = []\n",
    "production_designers = []\n",
    "set_decorators = []\n",
    "composers = []\n",
    "sound_department = []\n",
    "costume_designers = []\n",
    "make_up_artists = []\n",
    "\n",
    "for soup in soups:\n",
    "    \n",
    "    # Film ids\n",
    "    \n",
    "    id = custom_functions.scrape_id(soup)\n",
    "    ids_two.append(id)\n",
    "    \n",
    "    # Film titles\n",
    "    \n",
    "    title = custom_functions.scrape_title(soup)\n",
    "    titles.append(title)\n",
    "    \n",
    "    ## Release years\n",
    "    \n",
    "    year = custom_functions.scrape_year(soup)\n",
    "    years.append(year)\n",
    "    \n",
    "    ## Directors\n",
    "    \n",
    "    director_names = custom_functions.scrape_director(soup)\n",
    "    directors.append(director_names)\n",
    "        \n",
    "    ## Cast\n",
    "    \n",
    "    actors = custom_functions.scrape_cast(soup)\n",
    "    cast.append(actors)\n",
    "        \n",
    "    ## Country\n",
    "        \n",
    "    countries_of_origin = custom_functions.scrape_country(soup)\n",
    "    countries.append(countries_of_origin)\n",
    "        \n",
    "    ## Genres\n",
    "    \n",
    "    genre_names = custom_functions.scrape_genre(soup)\n",
    "    genres.append(genre_names)\n",
    "    \n",
    "    ## Production companies\n",
    "    \n",
    "    companies = custom_functions.scrape_production_company(soup)\n",
    "    production_companies.append(companies)\n",
    "    \n",
    "    ## Runtime\n",
    "    \n",
    "    runtime = custom_functions.scrape_runtime(soup)\n",
    "    runtimes.append(runtime)\n",
    "    \n",
    "    ## Languages\n",
    "    \n",
    "    language = custom_functions.scrape_languages(soup)\n",
    "    languages.append(language)\n",
    "    \n",
    "    ## Alternative titles\n",
    "    \n",
    "    alt_title = custom_functions.scrape_alt_titles(soup)\n",
    "    alt_titles.append(alt_title)\n",
    "    \n",
    "    ## Producers\n",
    "    \n",
    "    producer = custom_functions.scrape_people(soup, \"producer\")\n",
    "    producers.append(producer)\n",
    "    \n",
    "    ## Writers\n",
    "    \n",
    "    writer = custom_functions.scrape_people(soup, \"writer\")\n",
    "    writers.append(writer)\n",
    "    \n",
    "    ## Editors\n",
    "    editor = custom_functions.scrape_people(soup, \"editor\")\n",
    "    editors.append(editor)\n",
    "    \n",
    "    ## Cinematographers\n",
    "    \n",
    "    cinematographer = custom_functions.scrape_people(soup, \"cinematography\")\n",
    "    cinematographers.append(cinematographer)\n",
    "    \n",
    "    ## Production designers\n",
    "    \n",
    "    production_design = custom_functions.scrape_people(soup, \"production-design\")\n",
    "    production_designers.append(production_design)\n",
    "    \n",
    "    ## Set decorators\n",
    "    \n",
    "    set_decorator = custom_functions.scrape_people(soup, \"set-decoration\")\n",
    "    set_decorators.append(set_decorator)\n",
    "    \n",
    "    ## Composers\n",
    "    \n",
    "    composer = custom_functions.scrape_people(soup, \"composer\")\n",
    "    composers.append(composer)\n",
    "    \n",
    "    ## Sound department\n",
    "    \n",
    "    sound = custom_functions.scrape_people(soup, \"sound\")\n",
    "    sound_department.append(sound)\n",
    "    \n",
    "    ## Costume designer\n",
    "    \n",
    "    costume_designer = custom_functions.scrape_people(soup, \"costumes\")\n",
    "    costume_designers.append(costume_designer)\n",
    "    \n",
    "    ## Make-up artists\n",
    "    \n",
    "    make_up_artist = custom_functions.scrape_people(soup, \"make-up\")\n",
    "    make_up_artists.append(make_up_artist)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store everything into two dictionaries, turn them into dataframes and join them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_one = {\"id\": ids,\n",
    "         \"rating\": ratings}\n",
    "\n",
    "df_one = pd.DataFrame(d_one)\n",
    "\n",
    "d_two = {\"id\": ids_two,\n",
    "         \"title\": titles,\n",
    "         \"year\": years,\n",
    "         \"director\": directors,\n",
    "         \"actors\": cast,\n",
    "         \"genre\": genres,\n",
    "         \"country\": countries,\n",
    "         \"production_company\": production_companies,\n",
    "         \"runtime\": runtimes,\n",
    "         \"language\": languages,\n",
    "         \"alternative_titles\": alt_titles,\n",
    "         \"producers\": producers,\n",
    "         \"writer\": writers,\n",
    "         \"editor\": editors,\n",
    "         \"cinematographer\": cinematographers,\n",
    "         \"production_designer\": production_designers,\n",
    "         \"set_decorator\": set_decorators,\n",
    "         \"composer\": composers,\n",
    "         \"sound\": sound_department,\n",
    "         \"costumes\": costume_designers,\n",
    "         \"make_up\": make_up_artists\n",
    "        }\n",
    "\n",
    "df_two = pd.DataFrame(d_two)\n",
    "\n",
    "df = pd.merge(left = df_one, right = df_two, how = \"inner\", on = \"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a look at the first rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>director</th>\n",
       "      <th>actors</th>\n",
       "      <th>genre</th>\n",
       "      <th>country</th>\n",
       "      <th>production_company</th>\n",
       "      <th>runtime</th>\n",
       "      <th>...</th>\n",
       "      <th>producers</th>\n",
       "      <th>writer</th>\n",
       "      <th>editor</th>\n",
       "      <th>cinematographer</th>\n",
       "      <th>production_designer</th>\n",
       "      <th>set_decorator</th>\n",
       "      <th>composer</th>\n",
       "      <th>sound</th>\n",
       "      <th>costumes</th>\n",
       "      <th>make_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25849</td>\n",
       "      <td>7</td>\n",
       "      <td>I Was Nineteen</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>Konrad Wolf</td>\n",
       "      <td>Jaecki Schwarz;Vasiliy Livanov;Rolf Hoppe;Gali...</td>\n",
       "      <td>Drama;History</td>\n",
       "      <td>Germany;East Germany</td>\n",
       "      <td>DEFA;Künstlerische Arbeitsgruppe ''Babelsberg''</td>\n",
       "      <td>115.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Wolfgang Kohlhaase;Konrad Wolf</td>\n",
       "      <td>Evelyn Carow</td>\n",
       "      <td>Werner Bergmann</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189338</td>\n",
       "      <td>7</td>\n",
       "      <td>National Gallery</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Frederick Wiseman</td>\n",
       "      <td>Leanne Benjamin;Kausikan Rajeshkumar;Jo Shapco...</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>UK;USA;France</td>\n",
       "      <td>Gallery Films;Idéale Audience;Zipporah Films;C...</td>\n",
       "      <td>180.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Pierre-Olivier Bardet;Frederick Wiseman</td>\n",
       "      <td>Frederick Wiseman</td>\n",
       "      <td>Frederick Wiseman</td>\n",
       "      <td>John Davey</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Frederick Wiseman;Emmanuel Croset;Geoffrey Durcak</td>\n",
       "      <td>Conrad Shawcross</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>424212</td>\n",
       "      <td>7</td>\n",
       "      <td>So Long, My Son</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Wang Xiaoshuai</td>\n",
       "      <td>Wang Jingchun;Yong Mei;Qi Xi;Du Jiang;Ai Li-ya...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>China</td>\n",
       "      <td>Dongchun Films (Beijing);Hehe Pictures</td>\n",
       "      <td>185.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Jianü Han</td>\n",
       "      <td>Wang Xiaoshuai;Mei Ah</td>\n",
       "      <td>Lee Chatametikool</td>\n",
       "      <td>Kim Hyun-seok</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yingda Dong</td>\n",
       "      <td>Sergio López-Eraña;Miguel Calvo;Steve Miller;F...</td>\n",
       "      <td></td>\n",
       "      <td>Liu Jianglan;Zhang Peng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62934</td>\n",
       "      <td>7</td>\n",
       "      <td>The Strawberry Blonde</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>Raoul Walsh</td>\n",
       "      <td>James Cagney;Olivia de Havilland;Rita Hayworth...</td>\n",
       "      <td>Romance;Comedy;Music</td>\n",
       "      <td>USA</td>\n",
       "      <td>Warner Bros. Pictures</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Hal B. Wallis</td>\n",
       "      <td>Julius J. Epstein;Philip G. Epstein</td>\n",
       "      <td>William Holmes</td>\n",
       "      <td>James Wong Howe</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Heinz Roemheld</td>\n",
       "      <td>Robert B. Lee</td>\n",
       "      <td>Orry-Kelly</td>\n",
       "      <td>Perc Westmore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51599</td>\n",
       "      <td>7</td>\n",
       "      <td>The Promised Land</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>Andrzej Wajda</td>\n",
       "      <td>Daniel Olbrychski;Wojciech Pszoniak;Andrzej Se...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Zespól Filmowy \"X\";Film Polski Film Agency</td>\n",
       "      <td>170.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Andrzej Wajda;Władysław Stanisław Reymont</td>\n",
       "      <td>Zofia Dwornik;Halina Prugar-Ketling</td>\n",
       "      <td>Edward Kłosiński;Wacław Dybowski;Witold Soboci...</td>\n",
       "      <td>Tadeusz Kosarewicz</td>\n",
       "      <td>Maria Osiecka-Kuminek;Maciej Maria Putowski</td>\n",
       "      <td>Wojciech Kilar</td>\n",
       "      <td>Krzysztof Wodziński;Leszek Wronko</td>\n",
       "      <td>Danuta Kowner-Hałatek;Barbara Ptak</td>\n",
       "      <td>Halina Ber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  rating                  title    year           director  \\\n",
       "0   25849       7         I Was Nineteen  1968.0        Konrad Wolf   \n",
       "1  189338       7       National Gallery  2014.0  Frederick Wiseman   \n",
       "2  424212       7        So Long, My Son  2019.0     Wang Xiaoshuai   \n",
       "3   62934       7  The Strawberry Blonde  1941.0        Raoul Walsh   \n",
       "4   51599       7      The Promised Land  1975.0      Andrzej Wajda   \n",
       "\n",
       "                                              actors                 genre  \\\n",
       "0  Jaecki Schwarz;Vasiliy Livanov;Rolf Hoppe;Gali...         Drama;History   \n",
       "1  Leanne Benjamin;Kausikan Rajeshkumar;Jo Shapco...           Documentary   \n",
       "2  Wang Jingchun;Yong Mei;Qi Xi;Du Jiang;Ai Li-ya...                 Drama   \n",
       "3  James Cagney;Olivia de Havilland;Rita Hayworth...  Romance;Comedy;Music   \n",
       "4  Daniel Olbrychski;Wojciech Pszoniak;Andrzej Se...                 Drama   \n",
       "\n",
       "                country                                 production_company  \\\n",
       "0  Germany;East Germany    DEFA;Künstlerische Arbeitsgruppe ''Babelsberg''   \n",
       "1         UK;USA;France  Gallery Films;Idéale Audience;Zipporah Films;C...   \n",
       "2                 China             Dongchun Films (Beijing);Hehe Pictures   \n",
       "3                   USA                              Warner Bros. Pictures   \n",
       "4                Poland         Zespól Filmowy \"X\";Film Polski Film Agency   \n",
       "\n",
       "   runtime  ...                                producers  \\\n",
       "0    115.0  ...                                            \n",
       "1    180.0  ...  Pierre-Olivier Bardet;Frederick Wiseman   \n",
       "2    185.0  ...                                Jianü Han   \n",
       "3     97.0  ...                            Hal B. Wallis   \n",
       "4    170.0  ...                                            \n",
       "\n",
       "                                      writer  \\\n",
       "0             Wolfgang Kohlhaase;Konrad Wolf   \n",
       "1                          Frederick Wiseman   \n",
       "2                      Wang Xiaoshuai;Mei Ah   \n",
       "3        Julius J. Epstein;Philip G. Epstein   \n",
       "4  Andrzej Wajda;Władysław Stanisław Reymont   \n",
       "\n",
       "                                editor  \\\n",
       "0                         Evelyn Carow   \n",
       "1                    Frederick Wiseman   \n",
       "2                    Lee Chatametikool   \n",
       "3                       William Holmes   \n",
       "4  Zofia Dwornik;Halina Prugar-Ketling   \n",
       "\n",
       "                                     cinematographer production_designer  \\\n",
       "0                                    Werner Bergmann                       \n",
       "1                                         John Davey                       \n",
       "2                                      Kim Hyun-seok                       \n",
       "3                                    James Wong Howe                       \n",
       "4  Edward Kłosiński;Wacław Dybowski;Witold Soboci...  Tadeusz Kosarewicz   \n",
       "\n",
       "                                 set_decorator        composer  \\\n",
       "0                                                                \n",
       "1                                                                \n",
       "2                                                  Yingda Dong   \n",
       "3                                               Heinz Roemheld   \n",
       "4  Maria Osiecka-Kuminek;Maciej Maria Putowski  Wojciech Kilar   \n",
       "\n",
       "                                               sound  \\\n",
       "0                                                      \n",
       "1  Frederick Wiseman;Emmanuel Croset;Geoffrey Durcak   \n",
       "2  Sergio López-Eraña;Miguel Calvo;Steve Miller;F...   \n",
       "3                                      Robert B. Lee   \n",
       "4                  Krzysztof Wodziński;Leszek Wronko   \n",
       "\n",
       "                             costumes                  make_up  \n",
       "0                                                               \n",
       "1                    Conrad Shawcross                           \n",
       "2                                      Liu Jianglan;Zhang Peng  \n",
       "3                          Orry-Kelly            Perc Westmore  \n",
       "4  Danuta Kowner-Hałatek;Barbara Ptak               Halina Ber  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the empty string in the people-related columns with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['language', 'producers', 'writer', 'editor', 'cinematographer', 'production_designer', 'set_decorator', 'composer', 'sound', 'costumes', 'make_up']\n",
    "\n",
    "df[cols] = df[cols].apply(lambda x: x.replace(\"\", np.nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the columns by % of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_up                0.677812\n",
       "set_decorator          0.656346\n",
       "sound                  0.652074\n",
       "production_designer    0.604598\n",
       "costumes               0.545559\n",
       "alternative_titles     0.340873\n",
       "editor                 0.274068\n",
       "composer               0.272780\n",
       "producers              0.263285\n",
       "cinematographer        0.207128\n",
       "production_company     0.128251\n",
       "writer                 0.075316\n",
       "country                0.069789\n",
       "runtime                0.058700\n",
       "genre                  0.034148\n",
       "actors                 0.015429\n",
       "director               0.002374\n",
       "year                   0.000780\n",
       "language               0.000475\n",
       "title                  0.000000\n",
       "rating                 0.000000\n",
       "id                     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(lambda x: x.isnull().sum() / df.shape[0]).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split our dataframe into three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = df[['id', 'year', 'runtime', 'rating']]\n",
    "\n",
    "info = df[['id', 'title', 'genre', 'country', 'production_company', 'language', 'alternative_titles']]\n",
    "\n",
    "people = df[['id', 'director', 'actors', 'producers', 'writer', 'editor', 'cinematographer', 'production_designer', 'set_decorator', 'composer', 'sound', 'costumes', 'make_up']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the data in a PostgreSQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load username and passwords from environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.getenv(\"postgres_username\")\n",
    "password = os.getenv(\"postgres_psw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgconn = psycopg2.connect(host = \"localhost\", user = username, password = password)\n",
    "\n",
    "pgcursor = pgconn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this line to prevent errors when dropping the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  https://stackoverflow.com/questions/34484066/create-a-postgres-database-using-python\n",
    "\n",
    "pgconn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgcursor.execute(\"DROP DATABASE IF EXISTS mereghetti\")\n",
    "\n",
    "pgcursor.execute(\"CREATE DATABASE mereghetti\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine(f'postgresql://{username}:{password}@localhost:5432/mereghetti')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data in a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.866183042526245\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "facts.to_sql(con = engine, name = \"facts\", if_exists = \"replace\", index = False, chunksize = 100)\n",
    "info.to_sql(con = engine, name = \"info\", if_exists = \"replace\", index = False, chunksize = 100)\n",
    "people.to_sql(con = engine, name = \"people\", if_exists = \"replace\", index = False, chunksize = 100)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
